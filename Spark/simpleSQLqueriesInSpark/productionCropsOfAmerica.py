# -*- coding: utf-8 -*-
"""ProductionCropsOfAmerica.ipynb

@author: Nahuel Herpo

@release: Aug 8, 2022

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dcUNfCczllwypN8A19PBczyUVqRnceXT

**Setup**
"""

!sudo apt-get update

import os

# Install Java SDK 8
!apt-get install -y openjdk-8-jdk -qq > /dev/null
!echo $(/usr/libexec/java_home -v 1.8)

# Set environment variable
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
!echo 2 | update-alternatives --config java
!java -version    #check java version

root_path = 'drive/My Drive/Colab Notebooks/Conceptos\ y\ Aplicaciones\ de\ Big\ Data/SQL_Test_DBD/'

from google.colab import drive
drive.mount('/content/drive', force_remount = True)

# Install Spark for Python
!pip install pyspark

import os

# Install Java SDK 8
!apt-get install -y openjdk-8-jdk -qq > /dev/null
!echo $(/usr/libexec/java_home -v 1.8)

# Set environment variable
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
!echo 2 | update-alternatives --config java
!java -version    #check java version

# Create Spark Context
from pyspark import SparkContext
sc = SparkContext('local', 'test')

# Create Spark Session
from pyspark.sql import SparkSession
sparkSession = SparkSession.builder.appName('test').getOrCreate()

# Create SQL Context
from pyspark.sql import SQLContext, Row, functions as F, Window
from pyspark.sql.functions import udf, when, lit, count, col, array
from pyspark.sql.types import BooleanType, StringType, StructType, StructField, IntegerType, FloatType, LongType
sqlContext = SQLContext(sc)

# Persistence
from pyspark import StorageLevel

"""**Load Dataset**"""

american_crops = sparkSession.read.csv(root_path + 'Production_Crops_E_Americas.csv', sep=',', inferSchema=True, header=True)

american_crops.show()

american_crops.printSchema()

"""**SQL Queries**"""

american_crops.createOrReplaceTempView('american_crops')

# Print the crops that are from Argentina ordered by item code
df1 = sparkSession.sql('SELECT item_code, item_name, element_name, unit FROM american_crops WHERE area_name = "Argentina" ORDER BY item_code ASC')
df1.show()

# Print the amount of crops from Argentina
df2 = sparkSession.sql('SELECT area_name, COUNT(*) as count_of_crops FROM american_crops GROUP BY area_name HAVING area_name = "Argentina"')
df2.show()

# Print the amount of crops from Argentina
df3 = sparkSession.sql('SELECT area_name, COUNT(*) as count_of_crops FROM american_crops WHERE area_name = "Argentina" GROUP BY area_name')
df3.show()

"""SELECT nombre FROM deportes WHERE montocuota >=  ALL (SELECT montocuota FROM deportes)"""

# Print the country that has more crops registered
df4 = sparkSession.sql('SELECT area_name, COUNT(*) AS crops_count FROM american_crops GROUP BY area_name ORDER BY crops_count DESC LIMIT 1')
df4.show()
